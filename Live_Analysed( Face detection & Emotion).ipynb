{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face detection Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import logging as log\n",
    "import datetime as dt\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascPath = \"D:\\Analysis.in\\live\\haarcascade_frontalface_default.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "log.basicConfig(filename='webcam.log',level=log.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "anterior = 0\n",
    "\n",
    "while True:\n",
    "    if not video_capture.isOpened():\n",
    "        print('Unable to load camera.')\n",
    "        sleep(5)\n",
    "        pass\n",
    "\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = faceCascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(30, 30)\n",
    "    )\n",
    "\n",
    "    # Draw a rectangle around the faces\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    if anterior != len(faces):\n",
    "        anterior = len(faces)\n",
    "        log.info(\"faces: \"+str(len(faces))+\" at \"+str(dt.datetime.now()))\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working but not very accurate. work on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trial 1 emootion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'D:\\Analysis.in\\live\\fer2013.csv'\n",
    "image_size=(48,48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_fer2013():\n",
    "        data = pd.read_csv(\"D:\\\\Analysis.in\\\\live\\\\fer2013.csv\")\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'),image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "        return faces, emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#from load_and_process import load_fer2013\n",
    "#from load_and_process import preprocess_input\n",
    "#from models.cnn import mini_XCEPTION\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "image_array (Conv2D)         (None, 48, 48, 16)        800       \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 48, 48, 16)        12560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 48, 48, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 48, 48, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_13 (Averag (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 24, 24, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 24, 24, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_116 (Bat (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_117 (Bat (None, 12, 12, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_118 (Bat (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 6, 6, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_119 (Bat (None, 6, 6, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 3, 3, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_120 (Bat (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 3, 3, 7)           16135     \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_10  (None, 7)                 0         \n",
      "_________________________________________________________________\n",
      "predictions (Activation)     (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 642,935\n",
      "Trainable params: 641,463\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Activation, Convolution2D, Dropout, Conv2D\n",
    "from keras.layers import AveragePooling2D, BatchNormalization\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import SeparableConv2D\n",
    "from keras import layers\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def simple_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(7, 7), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(AveragePooling2D(pool_size=(2, 2), padding='same'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax',name='predictions'))\n",
    "    return model\n",
    "\n",
    "def simpler_CNN(input_shape, num_classes):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(5, 5), padding='same',\n",
    "                            name='image_array', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=16, kernel_size=(5, 5),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=32, kernel_size=(5, 5),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=64, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=128, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Convolution2D(filters=256, kernel_size=(1, 1), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Convolution2D(filters=num_classes, kernel_size=(3, 3),\n",
    "                            strides=(2, 2), padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    #model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax',name='predictions'))\n",
    "    return model\n",
    "\n",
    "def tiny_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(5, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(8, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(8, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(8, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "def mini_XCEPTION(input_shape, num_classes, l2_regularization=0.01):\n",
    "    regularization = l2(l2_regularization)\n",
    "\n",
    "    # base\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(img_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(8, (3, 3), strides=(1, 1), kernel_regularizer=regularization,\n",
    "                                            use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # module 1\n",
    "    residual = Conv2D(16, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 2\n",
    "    residual = Conv2D(32, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 3\n",
    "    residual = Conv2D(64, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    # module 4\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same',\n",
    "                        kernel_regularizer=regularization,\n",
    "                        use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "def big_XCEPTION(input_shape, num_classes):\n",
    "    img_input = Input(input_shape)\n",
    "    x = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n",
    "    x = BatchNormalization(name='block1_conv1_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv1_act')(x)\n",
    "    x = Conv2D(64, (3, 3), use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block1_conv2_bn')(x)\n",
    "    x = Activation('relu', name='block1_conv2_act')(x)\n",
    "\n",
    "    residual = Conv2D(128, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block2_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block2_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "\n",
    "    residual = Conv2D(256, (1, 1), strides=(2, 2),\n",
    "                      padding='same', use_bias=False)(x)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Activation('relu', name='block3_sepconv1_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv1_bn')(x)\n",
    "    x = Activation('relu', name='block3_sepconv2_act')(x)\n",
    "    x = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization(name='block3_sepconv2_bn')(x)\n",
    "\n",
    "    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = layers.add([x, residual])\n",
    "    x = Conv2D(num_classes, (3, 3),\n",
    "            #kernel_regularizer=regularization,\n",
    "            padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    output = Activation('softmax',name='predictions')(x)\n",
    "\n",
    "    model = Model(img_input, output)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (64, 64, 1)\n",
    "    num_classes = 7\n",
    "    #model = tiny_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    #model = mini_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    #model = big_XCEPTION(input_shape, num_classes)\n",
    "    #model.summary()\n",
    "    model = simple_CNN((48, 48, 1), num_classes)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 48, 48, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 46, 46, 8)    72          input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 46, 46, 8)    32          conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 46, 46, 8)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 44, 44, 8)    576         activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 44, 44, 8)    32          conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 44, 44, 8)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_49 (SeparableC (None, 44, 44, 16)   200         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 44, 44, 16)   64          separable_conv2d_49[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 44, 44, 16)   0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_50 (SeparableC (None, 44, 44, 16)   400         activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 44, 44, 16)   64          separable_conv2d_50[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 22, 22, 16)   128         activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling2D) (None, 22, 22, 16)   0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 22, 22, 16)   64          conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 22, 22, 16)   0           max_pooling2d_25[0][0]           \n",
      "                                                                 batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_51 (SeparableC (None, 22, 22, 32)   656         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 22, 22, 32)   128         separable_conv2d_51[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 22, 22, 32)   0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_52 (SeparableC (None, 22, 22, 32)   1312        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 22, 22, 32)   128         separable_conv2d_52[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 11, 11, 32)   512         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling2D) (None, 11, 11, 32)   0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 11, 11, 32)   128         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 11, 11, 32)   0           max_pooling2d_26[0][0]           \n",
      "                                                                 batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_53 (SeparableC (None, 11, 11, 64)   2336        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 11, 11, 64)   256         separable_conv2d_53[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 11, 11, 64)   0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_54 (SeparableC (None, 11, 11, 64)   4672        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 11, 11, 64)   256         separable_conv2d_54[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 6, 6, 64)     2048        add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 6, 6, 64)     0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 6, 6, 64)     256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 6, 6, 64)     0           max_pooling2d_27[0][0]           \n",
      "                                                                 batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_55 (SeparableC (None, 6, 6, 128)    8768        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 6, 6, 128)    512         separable_conv2d_55[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 128)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "separable_conv2d_56 (SeparableC (None, 6, 6, 128)    17536       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 6, 6, 128)    512         separable_conv2d_56[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 128)    8192        add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling2D) (None, 3, 3, 128)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 3, 3, 128)    512         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 3, 3, 128)    0           max_pooling2d_28[0][0]           \n",
      "                                                                 batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 7)      8071        add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 7)            0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Activation)        (None, 7)            0           global_average_pooling2d_11[0][0]\n",
      "==================================================================================================\n",
      "Total params: 58,423\n",
      "Trainable params: 56,951\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "898/897 [==============================] - 163s 182ms/step - loss: 1.7704 - accuracy: 0.3317 - val_loss: 1.5893 - val_accuracy: 0.4259\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-ffb42491ef3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                         validation_data=(xtest,ytest))\n\u001b[0m",
      "\u001b[1;32mD:\\Python\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    258\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[0mepoch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mcurrent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_acc'"
     ]
    }
   ],
   "source": [
    "# parameters\n",
    "batch_size = 32\n",
    "num_epochs = 50\n",
    "input_shape = (48, 48, 1)\n",
    "validation_split = .2\n",
    "verbose = 1\n",
    "num_classes = 7\n",
    "patience = 50\n",
    "base_path = (\"D:\\\\Analysis.in\\\\live\\\\_mini_XCEPTION.102-0.66.hdf5\")\n",
    "\n",
    "# data generator\n",
    "data_generator = ImageDataGenerator(\n",
    "                        featurewise_center=False,\n",
    "                        featurewise_std_normalization=False,\n",
    "                        rotation_range=10,\n",
    "                        width_shift_range=0.1,\n",
    "                        height_shift_range=0.1,\n",
    "                        zoom_range=.1,\n",
    "                        horizontal_flip=True)\n",
    "\n",
    "# model parameters/compilation\n",
    "model = mini_XCEPTION(input_shape, num_classes)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # callbacks\n",
    "log_file_path = base_path + '_emotion_training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "early_stop = EarlyStopping('val_loss', patience=patience)\n",
    "reduce_lr = ReduceLROnPlateau('val_loss', factor=0.1,\n",
    "                                  patience=int(patience/4), verbose=1)\n",
    "trained_models_path = base_path + '_mini_XCEPTION'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, 'val_loss', verbose=1,\n",
    "                                                    save_best_only=True)\n",
    "callbacks = [model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n",
    "# loading dataset\n",
    "faces, emotions = load_fer2013()\n",
    "faces = preprocess_input(faces)\n",
    "num_samples, num_classes = emotions.shape\n",
    "xtrain, xtest,ytrain,ytest = train_test_split(faces, emotions,test_size=0.2,shuffle=True)\n",
    "model.fit_generator(data_generator.flow(xtrain, ytrain,\n",
    "                                            batch_size),\n",
    "                        steps_per_epoch=len(xtrain) / batch_size,\n",
    "                        epochs=num_epochs, verbose=1, callbacks=callbacks,\n",
    "                        validation_data=(xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
